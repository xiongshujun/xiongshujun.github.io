- title: General Information
  type: map
  contents:
    - name: Full Name
      value: Shujun Xiong
    - name: Languages
      value: English, Mandarin, French

- title: Education
  type: time_table
  contents:
    - title: PhD in Neural Science
      institution: New York University
      year: 2024

    - title: B.A. in Mathematics
      institution: Columbia University
      year: 2020

- title: Research Experience
  type: time_table
  contents:
    - title: Undergraduate Researcher
      institution: Litwin-Kumar Lab, Zuckerman Institute, Columbia University
      year: Fall 2023 - Present
      description:
        - Characterized impact of dopaminergic heterogeneity in basal ganglia on deep reinforcement learning models for NeuroGym tasks
        - Analyzing behavior of high-dimensional limit cycles in Sompolinsky models
        - Serving as the Undergraduate Liaison for the Zuckerman Institute, organizing research talks and events for undergraduates
    - title: Caltech SURF Intern
      institution: Machine Learning and Instrument Autonomy, NASA-JPL
      year: Summer 2023
      description:
        - Trained source-specific models to improve methane plume detection on featureless and sparse aerial images
        - Leveraged different state-of-the-art and resource-constrained ensembling techniques to build explainable models for use with CarbonMapper

    - title: Undergraduate Intern (remote)
      institution: Li Bing Lab, Chinese Academy of Sciences
      year: Fall 2022
      description: Scripted Bayesian hyperparameter search over and ablation studies on encoder-decoder networks for unsupervised computer vision.

    - title: Columbia College Summer Research Fellow
      institution: MetaConscious Lab (Prof. Guangyu Robert Yang), MIT
      year: Summer 2022
      description:
        - Modeled real-world competitive behaviors, combining fear-reward psychology with evolutionary deep reinforcement learning agents
        - Discovered emergent properties of self-modeling in neural networks constrained by conflicts between innate and planned behaviors
        - Served as a peer mentor for Broad Summer Research Program students

    - title: Undergraduate Intern
      institution: Pe'er Lab, Columbia University
      year: Spring 2022
      description:
        - Applied hierarchical learning models in designed hyperbolic topologies to aid in protein discovery and classification (ICML 2022)
        - Investigated the utility and risks of sparse-data learning algorithms on queer community-networks and online data (TransTech 2022)

    - title: Broad Summer Research Student
      institution: Broad Institute of MIT and Harvard
      year: Summer 2021
      description:
        - Analyzed correlations in genes implicated in cancer and depression incidence using self-designed statistical tools (NDiSTEM 2021)

    - title: Laidlaw Scholar
      institution: Yao Lu, Columbia University
      year: Spring - Summer 2021
      description:
        - Designed and conducted an independent research project about the impact of COVID-19 on the transgender/nonbinary Chinese-American community
        - Conducted and transcribed oral history interviews, reviewing material in both Mandarin and English

    - title: Undergraduate Intern
      institution: Bin Xu, Columbia University
      year: Fall 2020 - Spring 2021
      description:
        - Cultured cerebral organoids with dystonia knock-outs. Collected mRNA-seq data, compared to schizophrenia-knock-out organoids.
        - Started a software group, wrote infrastructure to improve analysis of genetic data in schizophrenia and early-onset dystonia patients


- title: Academic Honors and Awards
  type: time_table
  contents:
    - year: 2024
      items:
        - MacCracken Fellowship
    - year: 2023
      items:
        - Rhodes Scholarship Nominee (~800 nationally)
    - year: 2022
      items:
        - Almaworks Fellowship
        - Columbia College Summer Research Fellowship (24%)
        - Columbia Research Travel Grant
    - year: 2021
      items:
        - Laidlaw Scholar (~1.5%)
